{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:33.350916Z",
     "iopub.status.busy": "2021-12-08T20:01:33.350359Z",
     "iopub.status.idle": "2021-12-08T20:01:37.924822Z",
     "shell.execute_reply": "2021-12-08T20:01:37.923827Z",
     "shell.execute_reply.started": "2021-12-08T20:01:33.350787Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "rng = np.random.RandomState(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:37.927351Z",
     "iopub.status.busy": "2021-12-08T20:01:37.926843Z",
     "iopub.status.idle": "2021-12-08T20:01:46.757789Z",
     "shell.execute_reply": "2021-12-08T20:01:46.75685Z",
     "shell.execute_reply.started": "2021-12-08T20:01:37.927313Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:46.760318Z",
     "iopub.status.busy": "2021-12-08T20:01:46.759972Z",
     "iopub.status.idle": "2021-12-08T20:01:56.591624Z",
     "shell.execute_reply": "2021-12-08T20:01:56.590709Z",
     "shell.execute_reply.started": "2021-12-08T20:01:46.760277Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons tensorflow-determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:56.593892Z",
     "iopub.status.busy": "2021-12-08T20:01:56.593532Z",
     "iopub.status.idle": "2021-12-08T20:01:57.49324Z",
     "shell.execute_reply": "2021-12-08T20:01:57.492341Z",
     "shell.execute_reply.started": "2021-12-08T20:01:56.593855Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.keras.layers import Layer, Embedding, Input, Dropout, Bidirectional, LSTM, Dense\n",
    "#from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from imblearn.metrics import specificity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.496775Z",
     "iopub.status.busy": "2021-12-08T20:01:57.496484Z",
     "iopub.status.idle": "2021-12-08T20:01:57.539416Z",
     "shell.execute_reply": "2021-12-08T20:01:57.53867Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.496724Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/financialphrasesemevalfiqa/title-sentiment.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.541069Z",
     "iopub.status.busy": "2021-12-08T20:01:57.540695Z",
     "iopub.status.idle": "2021-12-08T20:01:57.552798Z",
     "shell.execute_reply": "2021-12-08T20:01:57.55183Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.541032Z"
    }
   },
   "outputs": [],
   "source": [
    "data.title = data.title.astype(str)\n",
    "data.sentiment = data.sentiment.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.554674Z",
     "iopub.status.busy": "2021-12-08T20:01:57.554247Z",
     "iopub.status.idle": "2021-12-08T20:01:57.652204Z",
     "shell.execute_reply": "2021-12-08T20:01:57.651258Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.55464Z"
    }
   },
   "outputs": [],
   "source": [
    "data['title'] = data['title'].str.replace(r'[^\\w\\s]+', '')\n",
    "data['title'] = data['title'].str.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.653963Z",
     "iopub.status.busy": "2021-12-08T20:01:57.653614Z",
     "iopub.status.idle": "2021-12-08T20:01:57.65925Z",
     "shell.execute_reply": "2021-12-08T20:01:57.658457Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.653928Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data['title'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.662876Z",
     "iopub.status.busy": "2021-12-08T20:01:57.662491Z",
     "iopub.status.idle": "2021-12-08T20:01:57.667653Z",
     "shell.execute_reply": "2021-12-08T20:01:57.666641Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.662837Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 12697\n",
    "MAX_SEQUENCE_LENGTH = 225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O word embedding usado no método abaixo encontra-se em https://www.kaggle.com/yekenot/fasttext-crawl-300d-2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.670525Z",
     "iopub.status.busy": "2021-12-08T20:01:57.670158Z",
     "iopub.status.idle": "2021-12-08T20:01:57.67734Z",
     "shell.execute_reply": "2021-12-08T20:01:57.676366Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.670491Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_tokenizer_and_weights(X):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS,split=' ')\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    \n",
    "    weights = np.zeros((len(tokenizer.word_index)+1, 300))\n",
    "    with open(\"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\") as f:\n",
    "        next(f)\n",
    "        for l in f:\n",
    "            w = l.split(' ')\n",
    "            if w[0] in tokenizer.word_index:\n",
    "                weights[tokenizer.word_index[w[0]]] = np.array([float(x) for x in w[1:301]])\n",
    "    return tokenizer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:01:57.679394Z",
     "iopub.status.busy": "2021-12-08T20:01:57.678821Z",
     "iopub.status.idle": "2021-12-08T20:03:07.440266Z",
     "shell.execute_reply": "2021-12-08T20:03:07.439376Z",
     "shell.execute_reply.started": "2021-12-08T20:01:57.67934Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer, weights = prepare_tokenizer_and_weights(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.442012Z",
     "iopub.status.busy": "2021-12-08T20:03:07.441623Z",
     "iopub.status.idle": "2021-12-08T20:03:07.446831Z",
     "shell.execute_reply": "2021-12-08T20:03:07.445825Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.441968Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.448674Z",
     "iopub.status.busy": "2021-12-08T20:03:07.448149Z",
     "iopub.status.idle": "2021-12-08T20:03:07.463907Z",
     "shell.execute_reply": "2021-12-08T20:03:07.462781Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.448628Z"
    }
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.466031Z",
     "iopub.status.busy": "2021-12-08T20:03:07.465579Z",
     "iopub.status.idle": "2021-12-08T20:03:07.473389Z",
     "shell.execute_reply": "2021-12-08T20:03:07.472233Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.465998Z"
    }
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.475499Z",
     "iopub.status.busy": "2021-12-08T20:03:07.474878Z",
     "iopub.status.idle": "2021-12-08T20:03:07.483563Z",
     "shell.execute_reply": "2021-12-08T20:03:07.482659Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.475461Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.485343Z",
     "iopub.status.busy": "2021-12-08T20:03:07.484892Z",
     "iopub.status.idle": "2021-12-08T20:03:07.504913Z",
     "shell.execute_reply": "2021-12-08T20:03:07.503999Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.485304Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, 300, weights=[weights], input_length=(MAX_SEQUENCE_LENGTH,), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.506774Z",
     "iopub.status.busy": "2021-12-08T20:03:07.506369Z",
     "iopub.status.idle": "2021-12-08T20:03:07.512901Z",
     "shell.execute_reply": "2021-12-08T20:03:07.511595Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.506716Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_adam = AdamW(weight_decay=0.0,learning_rate=1e-5, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definições para uso do mecanismo de Atenção nas RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.515622Z",
     "iopub.status.busy": "2021-12-08T20:03:07.515141Z",
     "iopub.status.idle": "2021-12-08T20:03:07.536598Z",
     "shell.execute_reply": "2021-12-08T20:03:07.535589Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.515529Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers, constraints, initializers\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "\n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cc.gatech.edu/~dyang888/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da RNN (pode ser alterada para definir outras arquiteturas, como LSTMs bidirecionais, GRUs, Convnets, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.538513Z",
     "iopub.status.busy": "2021-12-08T20:03:07.538089Z",
     "iopub.status.idle": "2021-12-08T20:03:07.549629Z",
     "shell.execute_reply": "2021-12-08T20:03:07.548654Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.538463Z"
    }
   },
   "outputs": [],
   "source": [
    "def bilstm_model(input_shape):\n",
    "  X_indices = Input(input_shape)\n",
    "  embeddings = embedding_layer(X_indices)\n",
    "  #X = Dropout(0.5)(embeddings)\n",
    "  #X = Bidirectional(LSTM(100, return_sequences=True))(embeddings)\n",
    "  X = Bidirectional(LSTM(100, return_sequences=False))(embeddings) #descomentar se a camada de Attention não for usada\n",
    "  #X = AttentionWithContext()(X)\n",
    "  X = Dense(3, activation='softmax')(X)\n",
    "  model = Model(inputs=X_indices, outputs=X)\n",
    "  \n",
    "  model.summary()\n",
    "  plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento da RNN com 10-fold cross-validation e obtenção dos valores de benchmarking do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:03:07.553022Z",
     "iopub.status.busy": "2021-12-08T20:03:07.552667Z",
     "iopub.status.idle": "2021-12-08T20:10:22.324895Z",
     "shell.execute_reply": "2021-12-08T20:10:22.323956Z",
     "shell.execute_reply.started": "2021-12-08T20:03:07.552992Z"
    }
   },
   "outputs": [],
   "source": [
    "bilstm_mcc = []\n",
    "bilstm_f1 = []\n",
    "bilstm_precision = []\n",
    "bilstm_recall = []\n",
    "bilstm_bacc = []\n",
    "bilstm_spec = []\n",
    "\n",
    "fold = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=rng, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    model_bilstm = bilstm_model((MAX_SEQUENCE_LENGTH,))\n",
    "    model_bilstm.compile(optimizer=custom_adam,loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "    weight = {i : class_weights[i] for i in range(3)}\n",
    "    \n",
    "    model_bilstm.fit(X_train,y_train,epochs=10,verbose=1,batch_size=32, class_weight=weight)\n",
    "\n",
    "    y_pred = model_bilstm.predict(X_test, batch_size=32)\n",
    "    preds = np.argmax(y_pred, axis = 1)\n",
    "    \n",
    "    cnf_mtx = confusion_matrix(y_test, preds)\n",
    "    print(\"Fold #%i Confusion Matrix:\" % fold)\n",
    "    print(cnf_mtx)\n",
    "    \n",
    "    bilstm_mcc.append(matthews_corrcoef(y_test, preds))\n",
    "    bilstm_f1.append(f1_score(y_test, preds, average='weighted'))\n",
    "    bilstm_precision.append(precision_score(y_test, preds, average='weighted'))\n",
    "    bilstm_recall.append(recall_score(y_test, preds, average='weighted'))\n",
    "    bilstm_bacc.append(balanced_accuracy_score(y_test, preds))\n",
    "    bilstm_spec.append(specificity_score(y_test, preds, average='weighted'))\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.326823Z",
     "iopub.status.busy": "2021-12-08T20:10:22.326443Z",
     "iopub.status.idle": "2021-12-08T20:10:22.334652Z",
     "shell.execute_reply": "2021-12-08T20:10:22.333805Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.326784Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-MCC: {sum(bilstm_mcc) / len(bilstm_mcc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.335935Z",
     "iopub.status.busy": "2021-12-08T20:10:22.335637Z",
     "iopub.status.idle": "2021-12-08T20:10:22.347608Z",
     "shell.execute_reply": "2021-12-08T20:10:22.346758Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.335899Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-F1: {sum(bilstm_f1) / len(bilstm_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.349513Z",
     "iopub.status.busy": "2021-12-08T20:10:22.349171Z",
     "iopub.status.idle": "2021-12-08T20:10:22.357336Z",
     "shell.execute_reply": "2021-12-08T20:10:22.356292Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.349479Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-Precision: {sum(bilstm_precision) / len(bilstm_precision):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.359553Z",
     "iopub.status.busy": "2021-12-08T20:10:22.359055Z",
     "iopub.status.idle": "2021-12-08T20:10:22.366684Z",
     "shell.execute_reply": "2021-12-08T20:10:22.365655Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.359512Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-Recall: {sum(bilstm_recall) / len(bilstm_recall):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.368797Z",
     "iopub.status.busy": "2021-12-08T20:10:22.368324Z",
     "iopub.status.idle": "2021-12-08T20:10:22.374802Z",
     "shell.execute_reply": "2021-12-08T20:10:22.373688Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.36876Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-BACC: {sum(bilstm_bacc) / len(bilstm_bacc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.377094Z",
     "iopub.status.busy": "2021-12-08T20:10:22.376662Z",
     "iopub.status.idle": "2021-12-08T20:10:22.382823Z",
     "shell.execute_reply": "2021-12-08T20:10:22.381673Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.37706Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean-Specificity: {sum(bilstm_spec) / len(bilstm_spec):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T20:10:22.387638Z",
     "iopub.status.busy": "2021-12-08T20:10:22.38739Z",
     "iopub.status.idle": "2021-12-08T20:10:22.396045Z",
     "shell.execute_reply": "2021-12-08T20:10:22.394938Z",
     "shell.execute_reply.started": "2021-12-08T20:10:22.387616Z"
    }
   },
   "outputs": [],
   "source": [
    "data.title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

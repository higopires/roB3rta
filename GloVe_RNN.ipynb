{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom numpy.random import seed\nseed(42)\nrng = np.random.RandomState(42)\nimport tensorflow\ntensorflow.random.set_seed(42)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:39:47.668035Z","iopub.execute_input":"2021-11-23T17:39:47.668458Z","iopub.status.idle":"2021-11-23T17:39:52.4161Z","shell.execute_reply.started":"2021-11-23T17:39:47.668368Z","shell.execute_reply":"2021-11-23T17:39:52.415139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/data/glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:39:52.420813Z","iopub.execute_input":"2021-11-23T17:39:52.422952Z","iopub.status.idle":"2021-11-23T17:42:37.256439Z","shell.execute_reply.started":"2021-11-23T17:39:52.422896Z","shell.execute_reply":"2021-11-23T17:42:37.25539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip glove.6B.zip -d glove","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:42:37.262069Z","iopub.execute_input":"2021-11-23T17:42:37.264298Z","iopub.status.idle":"2021-11-23T17:42:58.59629Z","shell.execute_reply.started":"2021-11-23T17:42:37.264256Z","shell.execute_reply":"2021-11-23T17:42:58.59514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras -U","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:42:58.598712Z","iopub.execute_input":"2021-11-23T17:42:58.598999Z","iopub.status.idle":"2021-11-23T17:43:09.980497Z","shell.execute_reply.started":"2021-11-23T17:42:58.598955Z","shell.execute_reply":"2021-11-23T17:43:09.979539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons tensorflow-determinism","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:09.982244Z","iopub.execute_input":"2021-11-23T17:43:09.982613Z","iopub.status.idle":"2021-11-23T17:43:20.390817Z","shell.execute_reply.started":"2021-11-23T17:43:09.982571Z","shell.execute_reply":"2021-11-23T17:43:20.389835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow_addons.optimizers import AdamW\nfrom tensorflow.keras.layers import Layer, Embedding, Input, Dropout, Bidirectional, LSTM, Flatten, Dense\n#from tensorflow.compat.v1.keras.layers import CuDNNLSTM\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, matthews_corrcoef, f1_score, precision_score, recall_score, balanced_accuracy_score\nfrom imblearn.metrics import specificity_score","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:20.392423Z","iopub.execute_input":"2021-11-23T17:43:20.393163Z","iopub.status.idle":"2021-11-23T17:43:21.361575Z","shell.execute_reply.started":"2021-11-23T17:43:20.393116Z","shell.execute_reply":"2021-11-23T17:43:21.360493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/financialphrasesemevalfiqa/title-sentiment.csv',encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.365983Z","iopub.execute_input":"2021-11-23T17:43:21.36825Z","iopub.status.idle":"2021-11-23T17:43:21.425573Z","shell.execute_reply.started":"2021-11-23T17:43:21.368211Z","shell.execute_reply":"2021-11-23T17:43:21.424605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.431161Z","iopub.execute_input":"2021-11-23T17:43:21.43319Z","iopub.status.idle":"2021-11-23T17:43:21.469639Z","shell.execute_reply.started":"2021-11-23T17:43:21.433147Z","shell.execute_reply":"2021-11-23T17:43:21.468848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.473997Z","iopub.execute_input":"2021-11-23T17:43:21.476045Z","iopub.status.idle":"2021-11-23T17:43:21.492498Z","shell.execute_reply.started":"2021-11-23T17:43:21.476008Z","shell.execute_reply":"2021-11-23T17:43:21.491398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.title = data.title.astype(str)\ndata.sentiment = data.sentiment.astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.496093Z","iopub.execute_input":"2021-11-23T17:43:21.498088Z","iopub.status.idle":"2021-11-23T17:43:21.508Z","shell.execute_reply.started":"2021-11-23T17:43:21.498049Z","shell.execute_reply":"2021-11-23T17:43:21.506754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['title'] = data['title'].str.replace(r'[^\\w\\s]+', '')\ndata['title'] = data['title'].str.replace('\\s+', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.512243Z","iopub.execute_input":"2021-11-23T17:43:21.51434Z","iopub.status.idle":"2021-11-23T17:43:21.658182Z","shell.execute_reply.started":"2021-11-23T17:43:21.514291Z","shell.execute_reply":"2021-11-23T17:43:21.657173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['seq_length'] = data.title.apply(lambda x: len(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.659472Z","iopub.execute_input":"2021-11-23T17:43:21.659943Z","iopub.status.idle":"2021-11-23T17:43:21.670056Z","shell.execute_reply.started":"2021-11-23T17:43:21.659907Z","shell.execute_reply":"2021-11-23T17:43:21.669247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.seq_length.hist()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:21.671361Z","iopub.execute_input":"2021-11-23T17:43:21.671708Z","iopub.status.idle":"2021-11-23T17:43:22.05371Z","shell.execute_reply.started":"2021-11-23T17:43:21.671673Z","shell.execute_reply":"2021-11-23T17:43:22.052822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['title'] = data['title'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.055148Z","iopub.execute_input":"2021-11-23T17:43:22.055735Z","iopub.status.idle":"2021-11-23T17:43:22.065801Z","shell.execute_reply.started":"2021-11-23T17:43:22.055697Z","shell.execute_reply":"2021-11-23T17:43:22.065001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data['title'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.067206Z","iopub.execute_input":"2021-11-23T17:43:22.067771Z","iopub.status.idle":"2021-11-23T17:43:22.072831Z","shell.execute_reply.started":"2021-11-23T17:43:22.067732Z","shell.execute_reply":"2021-11-23T17:43:22.071558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_NB_WORDS = 12697\nMAX_SEQUENCE_LENGTH = 225","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.07457Z","iopub.execute_input":"2021-11-23T17:43:22.074986Z","iopub.status.idle":"2021-11-23T17:43:22.081705Z","shell.execute_reply.started":"2021-11-23T17:43:22.07495Z","shell.execute_reply":"2021-11-23T17:43:22.08081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=MAX_NB_WORDS,split=' ')\ntokenizer.fit_on_texts(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.08402Z","iopub.execute_input":"2021-11-23T17:43:22.084744Z","iopub.status.idle":"2021-11-23T17:43:22.221981Z","shell.execute_reply.started":"2021-11-23T17:43:22.084585Z","shell.execute_reply":"2021-11-23T17:43:22.221161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.224177Z","iopub.execute_input":"2021-11-23T17:43:22.224673Z","iopub.status.idle":"2021-11-23T17:43:22.376214Z","shell.execute_reply.started":"2021-11-23T17:43:22.224635Z","shell.execute_reply":"2021-11-23T17:43:22.375231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index\nprint('%s unique tokens.' % len(word_index))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.377652Z","iopub.execute_input":"2021-11-23T17:43:22.378027Z","iopub.status.idle":"2021-11-23T17:43:22.383571Z","shell.execute_reply.started":"2021-11-23T17:43:22.377988Z","shell.execute_reply":"2021-11-23T17:43:22.38236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nY = encoder.fit_transform(data['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.38514Z","iopub.execute_input":"2021-11-23T17:43:22.38575Z","iopub.status.idle":"2021-11-23T17:43:22.397628Z","shell.execute_reply.started":"2021-11-23T17:43:22.385713Z","shell.execute_reply":"2021-11-23T17:43:22.396569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.398956Z","iopub.execute_input":"2021-11-23T17:43:22.399417Z","iopub.status.idle":"2021-11-23T17:43:22.408913Z","shell.execute_reply.started":"2021-11-23T17:43:22.399379Z","shell.execute_reply":"2021-11-23T17:43:22.407836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = dict()\nf = open('./glove/glove.6B.300d.txt')\nfor line in f:\n\tvalues = line.split()\n\tword = values[0]\n\tcoefs = np.asarray(values[1:], dtype='float32')\n\tembeddings_index[word] = coefs\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:43:22.410591Z","iopub.execute_input":"2021-11-23T17:43:22.410959Z","iopub.status.idle":"2021-11-23T17:44:06.106814Z","shell.execute_reply.started":"2021-11-23T17:43:22.410924Z","shell.execute_reply":"2021-11-23T17:44:06.105888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total: %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.110666Z","iopub.execute_input":"2021-11-23T17:44:06.110935Z","iopub.status.idle":"2021-11-23T17:44:06.117291Z","shell.execute_reply.started":"2021-11-23T17:44:06.110907Z","shell.execute_reply":"2021-11-23T17:44:06.116206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nprint (vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.119511Z","iopub.execute_input":"2021-11-23T17:44:06.119925Z","iopub.status.idle":"2021-11-23T17:44:06.127715Z","shell.execute_reply.started":"2021-11-23T17:44:06.11989Z","shell.execute_reply":"2021-11-23T17:44:06.126674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create weight matrix\nembedding_matrix = np.zeros((vocab_size, 300))\nfor word, i in tokenizer.word_index.items():\n\tembedding_vector = embeddings_index.get(word)\n\tif embedding_vector is not None:\n\t\tembedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.129236Z","iopub.execute_input":"2021-11-23T17:44:06.129624Z","iopub.status.idle":"2021-11-23T17:44:06.174343Z","shell.execute_reply.started":"2021-11-23T17:44:06.129566Z","shell.execute_reply":"2021-11-23T17:44:06.173511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.175604Z","iopub.execute_input":"2021-11-23T17:44:06.176171Z","iopub.status.idle":"2021-11-23T17:44:06.183655Z","shell.execute_reply.started":"2021-11-23T17:44:06.176134Z","shell.execute_reply":"2021-11-23T17:44:06.182717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.185075Z","iopub.execute_input":"2021-11-23T17:44:06.185879Z","iopub.status.idle":"2021-11-23T17:44:06.194374Z","shell.execute_reply.started":"2021-11-23T17:44:06.185834Z","shell.execute_reply":"2021-11-23T17:44:06.19337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=(MAX_SEQUENCE_LENGTH,), trainable=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.195539Z","iopub.execute_input":"2021-11-23T17:44:06.19584Z","iopub.status.idle":"2021-11-23T17:44:06.215015Z","shell.execute_reply.started":"2021-11-23T17:44:06.195812Z","shell.execute_reply":"2021-11-23T17:44:06.214306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_adam = AdamW(weight_decay=0.0,learning_rate=1e-5, epsilon=1e-8)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.216358Z","iopub.execute_input":"2021-11-23T17:44:06.216932Z","iopub.status.idle":"2021-11-23T17:44:06.221952Z","shell.execute_reply.started":"2021-11-23T17:44:06.216894Z","shell.execute_reply":"2021-11-23T17:44:06.221162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nfrom tensorflow.keras import regularizers, constraints, initializers\n\ndef dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)\n\n\nclass AttentionWithContext(Layer):\n    \"\"\"\n    Attention operation, with a context/query vector, for temporal data.\n    Supports Masking.\n    Follows the work of Yang et al. [https://www.cc.gatech.edu/~dyang888/docs/naacl16.pdf]\n    \"Hierarchical Attention Networks for Document Classification\"\n    by using a context vector to assist the attention\n    # Input shape\n        3D tensor with shape: `(samples, steps, features)`.\n    # Output shape\n        2D tensor with shape: `(samples, features)`.\n    How to use:\n    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n    The dimensions are inferred based on the output shape of the RNN.\n    Note: The layer has been tested with Keras 2.0.6\n    Example:\n        model.add(LSTM(64, return_sequences=True))\n        model.add(AttentionWithContext())\n        # next add a Dense layer (for classification/regression) or whatever...\n    \"\"\"\n\n    def __init__(self,\n                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight(shape=(input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight(shape=(input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.22349Z","iopub.execute_input":"2021-11-23T17:44:06.223854Z","iopub.status.idle":"2021-11-23T17:44:06.2462Z","shell.execute_reply.started":"2021-11-23T17:44:06.223818Z","shell.execute_reply":"2021-11-23T17:44:06.245131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bilstm_model(input_shape):\n  X_indices = Input(input_shape)\n  embeddings = embedding_layer(X_indices)\n  #X = Dropout(0.5)(embeddings)\n  X = Bidirectional(LSTM(100, return_sequences=True))(embeddings)\n  #X = Bidirectional(LSTM(100, return_sequences=False))(embeddings) #Sem Attention\n  X = AttentionWithContext()(X)\n  X = Dense(3, activation='softmax')(X)\n  model = Model(inputs=X_indices, outputs=X)\n  \n  model.summary()\n  plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n    \n  return model","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.247814Z","iopub.execute_input":"2021-11-23T17:44:06.248556Z","iopub.status.idle":"2021-11-23T17:44:06.260258Z","shell.execute_reply.started":"2021-11-23T17:44:06.248512Z","shell.execute_reply":"2021-11-23T17:44:06.259288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bilstm_mcc = []\nbilstm_f1 = []\nbilstm_precision = []\nbilstm_recall = []\nbilstm_bacc = []\nbilstm_spec = []\n\nfold = 1\n\nskf = StratifiedKFold(n_splits=10, random_state=rng, shuffle=True)\nfor train_index, test_index in skf.split(X, Y):\n    model_bilstm = bilstm_model((MAX_SEQUENCE_LENGTH,))\n    model_bilstm.compile(optimizer=custom_adam,loss='sparse_categorical_crossentropy',metrics=['acc'])\n\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = Y[train_index], Y[test_index]\n    \n    class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n    weight = {i : class_weights[i] for i in range(3)}\n    \n    model_bilstm.fit(X_train,y_train,epochs=10,verbose=1,batch_size=32, class_weight=weight)\n\n    y_pred = model_bilstm.predict(X_test, batch_size=32)\n    preds = np.argmax(y_pred, axis = 1)\n    \n    cnf_mtx = confusion_matrix(y_test, preds)\n    print(\"Fold #%i Confusion Matrix:\" % fold)\n    print(cnf_mtx)\n    \n    bilstm_mcc.append(matthews_corrcoef(y_test, preds))\n    bilstm_f1.append(f1_score(y_test, preds, average='weighted'))\n    bilstm_precision.append(precision_score(y_test, preds, average='weighted'))\n    bilstm_recall.append(recall_score(y_test, preds, average='weighted'))\n    bilstm_bacc.append(balanced_accuracy_score(y_test, preds))\n    bilstm_spec.append(specificity_score(y_test, preds, average='weighted'))\n    fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:44:06.263688Z","iopub.execute_input":"2021-11-23T17:44:06.263976Z","iopub.status.idle":"2021-11-23T17:51:55.944175Z","shell.execute_reply.started":"2021-11-23T17:44:06.263945Z","shell.execute_reply":"2021-11-23T17:51:55.94306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-MCC: {sum(bilstm_mcc) / len(bilstm_mcc):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.945606Z","iopub.execute_input":"2021-11-23T17:51:55.94593Z","iopub.status.idle":"2021-11-23T17:51:55.95269Z","shell.execute_reply.started":"2021-11-23T17:51:55.945897Z","shell.execute_reply":"2021-11-23T17:51:55.951525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-F1: {sum(bilstm_f1) / len(bilstm_f1):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.954455Z","iopub.execute_input":"2021-11-23T17:51:55.955028Z","iopub.status.idle":"2021-11-23T17:51:55.961439Z","shell.execute_reply.started":"2021-11-23T17:51:55.954992Z","shell.execute_reply":"2021-11-23T17:51:55.960588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-Precision: {sum(bilstm_precision) / len(bilstm_precision):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.962838Z","iopub.execute_input":"2021-11-23T17:51:55.963177Z","iopub.status.idle":"2021-11-23T17:51:55.970233Z","shell.execute_reply.started":"2021-11-23T17:51:55.963142Z","shell.execute_reply":"2021-11-23T17:51:55.969139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-Recall: {sum(bilstm_recall) / len(bilstm_recall):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.971795Z","iopub.execute_input":"2021-11-23T17:51:55.972166Z","iopub.status.idle":"2021-11-23T17:51:55.978976Z","shell.execute_reply.started":"2021-11-23T17:51:55.972133Z","shell.execute_reply":"2021-11-23T17:51:55.977577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-BACC: {sum(bilstm_bacc) / len(bilstm_bacc):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.981402Z","iopub.execute_input":"2021-11-23T17:51:55.982165Z","iopub.status.idle":"2021-11-23T17:51:55.987985Z","shell.execute_reply.started":"2021-11-23T17:51:55.982038Z","shell.execute_reply":"2021-11-23T17:51:55.986871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean-Specificity: {sum(bilstm_spec) / len(bilstm_spec):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:51:55.989692Z","iopub.execute_input":"2021-11-23T17:51:55.990406Z","iopub.status.idle":"2021-11-23T17:51:55.996941Z","shell.execute_reply.started":"2021-11-23T17:51:55.990368Z","shell.execute_reply":"2021-11-23T17:51:55.995849Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
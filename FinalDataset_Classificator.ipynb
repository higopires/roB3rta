{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc\n"
      ],
      "metadata": {
        "id": "Ikt34cPaIarS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h6NeJlGD4sc"
      },
      "outputs": [],
      "source": [
        "!wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gensim scipy"
      ],
      "metadata": {
        "id": "2j3KYNWLEAvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip"
      ],
      "metadata": {
        "id": "OpkShOi7EB6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('cbow_s300.txt')"
      ],
      "metadata": {
        "id": "NU3lyUfoEe-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6rtdkObyG5_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/datasetTeste_Final.csv\")"
      ],
      "metadata": {
        "id": "qLUuY8DFFYh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "lRRIZ1D9HYKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import sub\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words \n",
        "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
        "    #text = remove_polish_letters(text)\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = sub(r\"[\\d,!?.\\/'+]\", \" \", text)\n",
        "    text = sub(r\"\\+\", \" mais \", text)\n",
        "    text = sub(r\",\", \" \", text)\n",
        "    text = sub(r\"\\.\", \" \", text)\n",
        "    text = sub(r\"!\", \" ! \", text)\n",
        "    text = sub(r\"\\?\", \" ? \", text)\n",
        "    text = sub(r\"'\", \" \", text)\n",
        "    text = sub(r\":\", \" : \", text)\n",
        "    text = sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text  "
      ],
      "metadata": {
        "id": "C1C_Zm1yHCEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.headlines = df.headlines.apply(lambda x: text_to_word_list(x))"
      ],
      "metadata": {
        "id": "B3COQE62HS-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_model = df.copy()\n",
        "file_model = file_model[file_model.headlines.str.len()>1]"
      ],
      "metadata": {
        "id": "uMKJEePlJiJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "sent = [row for row in file_model.headlines]\n",
        "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[sent]\n",
        "sentences[1]"
      ],
      "metadata": {
        "id": "u-4HY5ViJz_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import multiprocessing\n",
        "from time import time\n",
        "\n",
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     vector_size=300,\n",
        "                     sample=1e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)\n",
        "\n",
        "start = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=50000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
      ],
      "metadata": {
        "id": "DCUKvnpWSUqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
        "\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "metadata": {
        "id": "sZCwxUDlSq-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "VVnOqDztTjHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_export = file_model.copy()\n",
        "file_export['old_headlines'] = file_export.headlines\n",
        "file_export.old_headlines = file_export.old_headlines.str.join(' ')\n",
        "file_export.headlines = file_export.headlines.apply(lambda x: ' '.join(bigram[x]))\n",
        "#file_export.compound = file_export.compound.astype('int8')"
      ],
      "metadata": {
        "id": "Fil9yizkTnUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "FMndWlV2UB-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = Word2Vec.load(\"/content/word2vec.model\").wv"
      ],
      "metadata": {
        "id": "Hd3j-2A5UHMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(n_clusters=3, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
      ],
      "metadata": {
        "id": "vX7GtRICULMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similar_by_vector(\"bolsonaro\", topn=10, restrict_vocab=None)"
      ],
      "metadata": {
        "id": "oS8Bfmh9UUVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_cluster_index = 1\n",
        "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
        "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
      ],
      "metadata": {
        "id": "YA10l5HLXqfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = pd.DataFrame(list(word_vectors.index_to_key))\n",
        "words.columns = ['words']\n",
        "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
        "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
        "words.cluster = words.cluster.apply(lambda x: x[0])"
      ],
      "metadata": {
        "id": "aJCkur0qVJeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
        "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
        "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
      ],
      "metadata": {
        "id": "EREaP6Y-Xj_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "id": "XAkWOcfNXuWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
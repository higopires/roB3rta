{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf9ZmMFPXOD_"
      },
      "outputs": [],
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UseeMGx1XX1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def remove_empty_lines(filename):\n",
        "    if not os.path.isfile(filename):\n",
        "        print(\"{} does not exist \".format(filename))\n",
        "        return\n",
        "    with open(filename) as filehandle:\n",
        "        lines = filehandle.readlines()\n",
        "\n",
        "    with open(filename, 'w') as filehandle:\n",
        "        lines = filter(lambda x: x.strip(), lines)\n",
        "        filehandle.writelines(lines)"
      ],
      "metadata": {
        "id": "reO4lk6BPq9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_empty_lines('/content/drive/MyDrive/Final.txt')"
      ],
      "metadata": {
        "id": "cB4ZNgyDP2AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "lines = open('/content/drive/MyDrive/Final.txt').readlines()\n",
        "random.shuffle(lines)\n",
        "open('/content/drive/MyDrive/Final_Shuffled.txt', 'w').writelines(lines)"
      ],
      "metadata": {
        "id": "4KtE7uwAHErw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/drive/MyDrive/Final_Shuffled.txt"
      ],
      "metadata": {
        "id": "_ElnLczxEOku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!shuf -n 5 /content/drive/MyDrive/Final_Shuffled.txt"
      ],
      "metadata": {
        "id": "moQqAxe3Ebnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "MAXQwaysNnV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a subset of first 44362 lines for training\n",
        "#TRAIN_SIZE = 44362 #@param {type:\"integer\"}\n",
        "#!(head -n $TRAIN_SIZE /content/drive/MyDrive/Final_Shuffled.txt) > data/train.txt"
      ],
      "metadata": {
        "id": "ubu47deYNTbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a subset of next 443 lines for validation\n",
        "#VAL_SIZE = 443 #@param {type:\"integer\"}\n",
        "#!(sed -n {TRAIN_SIZE + 1},{TRAIN_SIZE + VAL_SIZE}p /content/drive/MyDrive/Final_Shuffled.txt) > data/dev.txt"
      ],
      "metadata": {
        "id": "xjF80FLROAxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "#paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files='/content/drive/MyDrive/Final_Shuffled.txt', vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "metadata": {
        "id": "EsbdoMf3mASs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir roB3rta\n",
        "tokenizer.save_model(\"roB3rta\")"
      ],
      "metadata": {
        "id": "Hl46w21gmV-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./roB3rta/vocab.json\",\n",
        "    \"./roB3rta/merges.txt\",\n",
        ")"
      ],
      "metadata": {
        "id": "oDHIFGpEmcU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "metadata": {
        "id": "UgBZLQKhmkBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Ações da Bolsa de Valores\")"
      ],
      "metadata": {
        "id": "dD8iW5RzmmQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Ações da Bolsa de Valores\").tokens"
      ],
      "metadata": {
        "id": "UcixvbOkmr4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=512,\n",
        "    num_attention_heads=8,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "metadata": {
        "id": "lWvo7w8jmxIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./roB3rta\", max_len=512)"
      ],
      "metadata": {
        "id": "lNgxkP_km1kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "metadata": {
        "id": "608w0CIbm6j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()\n",
        "# => 84 million parameters"
      ],
      "metadata": {
        "id": "DNYJfyx2m_RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d /content/drive/MyDrive/Final_Shuffled.txt ./shards/shard_"
      ],
      "metadata": {
        "id": "yJcoprKw0063"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "h8JLUm-3WfqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "files = glob.glob('shards/*')\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('text', data_files=files, split='train')"
      ],
      "metadata": {
        "id": "yXlir9qyWOFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(examples):\n",
        "  return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=96)\n",
        "\n",
        "dataset = dataset.map(encode, batched=True)\n",
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
      ],
      "metadata": {
        "id": "McZbtHdvWp3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#from transformers import LineByLineTextDataset\n",
        "#\n",
        "#dataset = LineByLineTextDataset(\n",
        "#    tokenizer=tokenizer,\n",
        "#    file_path=\"/content/drive/MyDrive/Final_Shuffled.txt\",\n",
        "#    block_size=128,\n",
        "#)"
      ],
      "metadata": {
        "id": "y7ZZPsQFnGks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "metadata": {
        "id": "76IhHbcxpaqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roB3rta\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    fp16=True,\n",
        "    half_precision_backend='amp',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "tENzajnWY9AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "metadata": {
        "id": "PINs7snxiWcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('apex')"
      ],
      "metadata": {
        "id": "EVNTApqgiqPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install AMP"
      ],
      "metadata": {
        "id": "x1zMyzUQmUgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "metadata": {
        "id": "Tb5MMmAYixWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "fQ67oTuXY_sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./roB3rta\")"
      ],
      "metadata": {
        "id": "rx_1feAXZELE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}